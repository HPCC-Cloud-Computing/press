{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kv/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", input_shape=(10, 1), filters=4, kernel_size=2)`\n",
      "/home/kv/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=4, kernel_size=2)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_39 (Conv1D)           (None, 9, 4)              12        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 4, 4)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 3, 4)              36        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1, 4)              0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 53\n",
      "Trainable params: 53\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(710, 10, 1)\n",
      "Train on 568 samples, validate on 142 samples\n",
      "Epoch 1/200\n",
      "568/568 [==============================] - 1s 912us/step - loss: 43445236.2077 - mean_absolute_error: 5969.7157 - val_loss: 40494557.2254 - val_mean_absolute_error: 5930.8447\n",
      "Epoch 2/200\n",
      "568/568 [==============================] - 0s 187us/step - loss: 7479166.6637 - mean_absolute_error: 2397.3580 - val_loss: 3532377.2183 - val_mean_absolute_error: 1711.1601\n",
      "Epoch 3/200\n",
      "568/568 [==============================] - 0s 197us/step - loss: 479571.8087 - mean_absolute_error: 514.4109 - val_loss: 214763.3329 - val_mean_absolute_error: 328.2304\n",
      "Epoch 4/200\n",
      "568/568 [==============================] - 0s 188us/step - loss: 96139.1395 - mean_absolute_error: 225.1086 - val_loss: 199748.2686 - val_mean_absolute_error: 313.9066\n",
      "Epoch 5/200\n",
      "568/568 [==============================] - 0s 187us/step - loss: 93426.3145 - mean_absolute_error: 221.0899 - val_loss: 198882.6046 - val_mean_absolute_error: 312.6472\n",
      "Epoch 6/200\n",
      "568/568 [==============================] - 0s 171us/step - loss: 92921.9693 - mean_absolute_error: 220.6410 - val_loss: 196330.3548 - val_mean_absolute_error: 311.1394\n",
      "Epoch 7/200\n",
      "568/568 [==============================] - 0s 180us/step - loss: 91513.9247 - mean_absolute_error: 218.7698 - val_loss: 195511.2251 - val_mean_absolute_error: 309.8083\n",
      "Epoch 8/200\n",
      "568/568 [==============================] - 0s 181us/step - loss: 90877.2544 - mean_absolute_error: 218.2982 - val_loss: 192001.8711 - val_mean_absolute_error: 307.7677\n",
      "Epoch 9/200\n",
      "568/568 [==============================] - 0s 181us/step - loss: 89471.8499 - mean_absolute_error: 216.1911 - val_loss: 191902.8851 - val_mean_absolute_error: 306.7309\n",
      "Epoch 10/200\n",
      "568/568 [==============================] - 0s 174us/step - loss: 88654.5351 - mean_absolute_error: 215.3591 - val_loss: 188518.0247 - val_mean_absolute_error: 304.2436\n",
      "Epoch 11/200\n",
      "568/568 [==============================] - 0s 171us/step - loss: 87307.0560 - mean_absolute_error: 213.8299 - val_loss: 185120.0184 - val_mean_absolute_error: 301.9937\n",
      "Epoch 12/200\n",
      "568/568 [==============================] - 0s 175us/step - loss: 86425.1974 - mean_absolute_error: 212.1949 - val_loss: 187421.8381 - val_mean_absolute_error: 303.0457\n",
      "Epoch 13/200\n",
      "568/568 [==============================] - 0s 178us/step - loss: 85135.4583 - mean_absolute_error: 210.9162 - val_loss: 180461.6128 - val_mean_absolute_error: 297.7853\n",
      "Epoch 14/200\n",
      "568/568 [==============================] - 0s 179us/step - loss: 83606.1911 - mean_absolute_error: 210.0286 - val_loss: 176910.5182 - val_mean_absolute_error: 295.3143\n",
      "Epoch 15/200\n",
      "568/568 [==============================] - 0s 188us/step - loss: 82327.7910 - mean_absolute_error: 208.1602 - val_loss: 176063.5492 - val_mean_absolute_error: 293.6360\n",
      "Epoch 16/200\n",
      "568/568 [==============================] - 0s 184us/step - loss: 80405.8788 - mean_absolute_error: 205.8367 - val_loss: 171171.3003 - val_mean_absolute_error: 290.7018\n",
      "Epoch 17/200\n",
      "568/568 [==============================] - 0s 178us/step - loss: 80148.6931 - mean_absolute_error: 204.6817 - val_loss: 169708.3757 - val_mean_absolute_error: 288.4192\n",
      "Epoch 18/200\n",
      "568/568 [==============================] - 0s 183us/step - loss: 78693.5074 - mean_absolute_error: 203.9287 - val_loss: 172700.0175 - val_mean_absolute_error: 291.1826\n",
      "Epoch 19/200\n",
      "568/568 [==============================] - 0s 176us/step - loss: 76331.4049 - mean_absolute_error: 200.2658 - val_loss: 162944.9759 - val_mean_absolute_error: 282.9542\n",
      "Epoch 20/200\n",
      "568/568 [==============================] - 0s 196us/step - loss: 74951.2649 - mean_absolute_error: 199.2258 - val_loss: 162967.3344 - val_mean_absolute_error: 282.3879\n",
      "Epoch 21/200\n",
      "568/568 [==============================] - 0s 194us/step - loss: 73291.3405 - mean_absolute_error: 196.9221 - val_loss: 158405.0572 - val_mean_absolute_error: 278.2439\n",
      "Epoch 22/200\n",
      "568/568 [==============================] - 0s 187us/step - loss: 72183.0498 - mean_absolute_error: 195.3727 - val_loss: 153220.1466 - val_mean_absolute_error: 274.4679\n",
      "Epoch 23/200\n",
      "568/568 [==============================] - 0s 194us/step - loss: 70442.0039 - mean_absolute_error: 191.8222 - val_loss: 149974.4098 - val_mean_absolute_error: 271.6212\n",
      "Epoch 24/200\n",
      "568/568 [==============================] - 0s 188us/step - loss: 68600.7237 - mean_absolute_error: 190.6338 - val_loss: 146497.6630 - val_mean_absolute_error: 268.5352\n",
      "Epoch 25/200\n",
      "568/568 [==============================] - 0s 191us/step - loss: 67364.5928 - mean_absolute_error: 188.1504 - val_loss: 147199.3885 - val_mean_absolute_error: 268.4035\n",
      "Epoch 26/200\n",
      "568/568 [==============================] - 0s 186us/step - loss: 65535.7892 - mean_absolute_error: 187.2919 - val_loss: 140341.1569 - val_mean_absolute_error: 262.6633\n",
      "Epoch 27/200\n",
      "568/568 [==============================] - 0s 191us/step - loss: 64512.5027 - mean_absolute_error: 185.4005 - val_loss: 137171.3304 - val_mean_absolute_error: 259.6409\n",
      "Epoch 28/200\n",
      "568/568 [==============================] - 0s 185us/step - loss: 63398.1893 - mean_absolute_error: 182.2097 - val_loss: 137963.1698 - val_mean_absolute_error: 259.7244\n",
      "Epoch 29/200\n",
      "568/568 [==============================] - 0s 185us/step - loss: 60644.7358 - mean_absolute_error: 179.5436 - val_loss: 131280.1228 - val_mean_absolute_error: 253.7979\n",
      "Epoch 30/200\n",
      "568/568 [==============================] - 0s 184us/step - loss: 59913.7276 - mean_absolute_error: 178.4301 - val_loss: 128595.7396 - val_mean_absolute_error: 250.9365\n",
      "Epoch 31/200\n",
      "568/568 [==============================] - 0s 188us/step - loss: 57681.8908 - mean_absolute_error: 174.7586 - val_loss: 131128.4804 - val_mean_absolute_error: 253.8040\n",
      "Epoch 32/200\n",
      "568/568 [==============================] - 0s 175us/step - loss: 56228.0761 - mean_absolute_error: 173.3182 - val_loss: 121986.8477 - val_mean_absolute_error: 244.5940\n",
      "Epoch 33/200\n",
      "568/568 [==============================] - 0s 181us/step - loss: 55242.1004 - mean_absolute_error: 170.8967 - val_loss: 120118.4798 - val_mean_absolute_error: 242.2305\n",
      "Epoch 34/200\n",
      "568/568 [==============================] - 0s 223us/step - loss: 53728.8050 - mean_absolute_error: 168.8174 - val_loss: 116367.5690 - val_mean_absolute_error: 238.7238\n",
      "Epoch 35/200\n",
      "568/568 [==============================] - 0s 238us/step - loss: 52502.9575 - mean_absolute_error: 167.0006 - val_loss: 118362.2650 - val_mean_absolute_error: 241.0852\n",
      "Epoch 36/200\n",
      "568/568 [==============================] - 0s 231us/step - loss: 51648.9572 - mean_absolute_error: 166.1726 - val_loss: 110910.5311 - val_mean_absolute_error: 232.7912\n",
      "Epoch 37/200\n",
      "568/568 [==============================] - 0s 195us/step - loss: 49407.0652 - mean_absolute_error: 162.8598 - val_loss: 114309.6767 - val_mean_absolute_error: 237.3471\n",
      "Epoch 38/200\n",
      "568/568 [==============================] - 0s 226us/step - loss: 48917.9996 - mean_absolute_error: 162.1720 - val_loss: 105165.8968 - val_mean_absolute_error: 226.7174\n",
      "Epoch 39/200\n",
      "568/568 [==============================] - 0s 181us/step - loss: 47063.0336 - mean_absolute_error: 158.0015 - val_loss: 102265.0341 - val_mean_absolute_error: 223.5690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200\n",
      "568/568 [==============================] - 0s 196us/step - loss: 46063.0472 - mean_absolute_error: 157.5470 - val_loss: 100046.2199 - val_mean_absolute_error: 221.2276\n",
      "Epoch 41/200\n",
      "568/568 [==============================] - 0s 191us/step - loss: 44520.4453 - mean_absolute_error: 154.4267 - val_loss: 96719.1821 - val_mean_absolute_error: 217.3049\n",
      "Epoch 42/200\n",
      "568/568 [==============================] - 0s 192us/step - loss: 43174.8769 - mean_absolute_error: 152.3752 - val_loss: 94322.1673 - val_mean_absolute_error: 214.0476\n",
      "Epoch 43/200\n",
      "568/568 [==============================] - 0s 181us/step - loss: 42435.7896 - mean_absolute_error: 150.4228 - val_loss: 95351.4421 - val_mean_absolute_error: 216.2203\n",
      "Epoch 44/200\n",
      "568/568 [==============================] - 0s 205us/step - loss: 41165.5470 - mean_absolute_error: 148.8924 - val_loss: 94292.9797 - val_mean_absolute_error: 215.4196\n",
      "Epoch 45/200\n",
      "568/568 [==============================] - 0s 193us/step - loss: 39934.6235 - mean_absolute_error: 147.0048 - val_loss: 86477.1158 - val_mean_absolute_error: 204.9106\n",
      "Epoch 46/200\n",
      "568/568 [==============================] - 0s 176us/step - loss: 38355.6388 - mean_absolute_error: 143.9982 - val_loss: 84537.8438 - val_mean_absolute_error: 202.5967\n",
      "Epoch 47/200\n",
      "568/568 [==============================] - 0s 179us/step - loss: 37262.0002 - mean_absolute_error: 140.6346 - val_loss: 82437.9369 - val_mean_absolute_error: 199.3159\n",
      "Epoch 48/200\n",
      "568/568 [==============================] - 0s 181us/step - loss: 36261.4006 - mean_absolute_error: 139.0271 - val_loss: 79692.8556 - val_mean_absolute_error: 196.2664\n",
      "Epoch 49/200\n",
      "568/568 [==============================] - 0s 202us/step - loss: 34940.1983 - mean_absolute_error: 137.3448 - val_loss: 77497.7764 - val_mean_absolute_error: 193.2494\n",
      "Epoch 50/200\n",
      "568/568 [==============================] - 0s 173us/step - loss: 33960.4946 - mean_absolute_error: 136.8617 - val_loss: 75763.2731 - val_mean_absolute_error: 191.3888\n",
      "Epoch 51/200\n",
      "568/568 [==============================] - 0s 178us/step - loss: 32999.8059 - mean_absolute_error: 133.4149 - val_loss: 74878.0279 - val_mean_absolute_error: 190.4249\n",
      "Epoch 52/200\n",
      "568/568 [==============================] - 0s 178us/step - loss: 31960.7477 - mean_absolute_error: 131.5180 - val_loss: 72175.8034 - val_mean_absolute_error: 186.6182\n",
      "Epoch 53/200\n",
      "568/568 [==============================] - 0s 226us/step - loss: 31591.4874 - mean_absolute_error: 131.2600 - val_loss: 78452.5973 - val_mean_absolute_error: 198.0287\n",
      "Epoch 54/200\n",
      "568/568 [==============================] - 0s 178us/step - loss: 30137.9424 - mean_absolute_error: 128.8599 - val_loss: 68387.2519 - val_mean_absolute_error: 179.9473\n",
      "Epoch 55/200\n",
      "568/568 [==============================] - 0s 191us/step - loss: 29963.4942 - mean_absolute_error: 127.3549 - val_loss: 65864.9238 - val_mean_absolute_error: 177.4809\n",
      "Epoch 56/200\n",
      "568/568 [==============================] - 0s 212us/step - loss: 28374.8606 - mean_absolute_error: 123.7488 - val_loss: 69879.2772 - val_mean_absolute_error: 184.5833\n",
      "Epoch 57/200\n",
      "568/568 [==============================] - 0s 181us/step - loss: 27481.0047 - mean_absolute_error: 122.3836 - val_loss: 62381.7584 - val_mean_absolute_error: 171.6486\n",
      "Epoch 58/200\n",
      "568/568 [==============================] - 0s 199us/step - loss: 27545.4909 - mean_absolute_error: 122.0449 - val_loss: 63319.6250 - val_mean_absolute_error: 173.6218\n",
      "Epoch 59/200\n",
      "568/568 [==============================] - 0s 224us/step - loss: 25653.5629 - mean_absolute_error: 118.2025 - val_loss: 59445.7595 - val_mean_absolute_error: 166.9056\n",
      "Epoch 60/200\n",
      "568/568 [==============================] - 0s 242us/step - loss: 25243.2585 - mean_absolute_error: 117.0780 - val_loss: 59783.8532 - val_mean_absolute_error: 167.9568\n",
      "Epoch 61/200\n",
      "568/568 [==============================] - 0s 176us/step - loss: 24433.7678 - mean_absolute_error: 114.7353 - val_loss: 66287.8297 - val_mean_absolute_error: 183.1067\n",
      "Epoch 62/200\n",
      "568/568 [==============================] - 0s 179us/step - loss: 24301.5878 - mean_absolute_error: 115.4381 - val_loss: 55235.9441 - val_mean_absolute_error: 160.2502\n",
      "Epoch 63/200\n",
      "568/568 [==============================] - 0s 183us/step - loss: 22935.0741 - mean_absolute_error: 111.8329 - val_loss: 54130.1533 - val_mean_absolute_error: 158.6129\n",
      "Epoch 64/200\n",
      "568/568 [==============================] - 0s 176us/step - loss: 22403.4314 - mean_absolute_error: 110.7419 - val_loss: 52330.7634 - val_mean_absolute_error: 155.7707\n",
      "Epoch 65/200\n",
      "568/568 [==============================] - 0s 178us/step - loss: 21570.9324 - mean_absolute_error: 108.2612 - val_loss: 50651.0346 - val_mean_absolute_error: 152.9912\n",
      "Epoch 66/200\n",
      "568/568 [==============================] - 0s 183us/step - loss: 20899.3421 - mean_absolute_error: 106.5279 - val_loss: 52268.4507 - val_mean_absolute_error: 158.5916\n",
      "Epoch 67/200\n",
      "568/568 [==============================] - 0s 191us/step - loss: 20533.9076 - mean_absolute_error: 106.7460 - val_loss: 48590.7056 - val_mean_absolute_error: 148.7796\n",
      "Epoch 68/200\n",
      "568/568 [==============================] - 0s 252us/step - loss: 19721.8866 - mean_absolute_error: 103.5788 - val_loss: 47894.1607 - val_mean_absolute_error: 150.3024\n",
      "Epoch 69/200\n",
      "568/568 [==============================] - 0s 209us/step - loss: 19119.9823 - mean_absolute_error: 102.0160 - val_loss: 46632.9320 - val_mean_absolute_error: 148.5572\n",
      "Epoch 70/200\n",
      "568/568 [==============================] - 0s 239us/step - loss: 18353.1006 - mean_absolute_error: 100.0774 - val_loss: 44171.5082 - val_mean_absolute_error: 143.4474\n",
      "Epoch 71/200\n",
      "568/568 [==============================] - 0s 223us/step - loss: 18384.8637 - mean_absolute_error: 99.2055 - val_loss: 42771.9691 - val_mean_absolute_error: 140.8507\n",
      "Epoch 72/200\n",
      "568/568 [==============================] - 0s 250us/step - loss: 17645.1084 - mean_absolute_error: 98.6651 - val_loss: 41724.5745 - val_mean_absolute_error: 139.5499\n",
      "Epoch 73/200\n",
      "568/568 [==============================] - 0s 228us/step - loss: 16795.6599 - mean_absolute_error: 95.8132 - val_loss: 40114.7956 - val_mean_absolute_error: 136.3804\n",
      "Epoch 74/200\n",
      "568/568 [==============================] - 0s 184us/step - loss: 16656.3187 - mean_absolute_error: 95.4817 - val_loss: 38701.0894 - val_mean_absolute_error: 133.7394\n",
      "Epoch 75/200\n",
      "568/568 [==============================] - 0s 278us/step - loss: 16109.7011 - mean_absolute_error: 93.8950 - val_loss: 41045.9524 - val_mean_absolute_error: 136.1567\n",
      "Epoch 76/200\n",
      "568/568 [==============================] - 0s 267us/step - loss: 15889.1895 - mean_absolute_error: 92.7067 - val_loss: 36460.1639 - val_mean_absolute_error: 130.2494\n",
      "Epoch 77/200\n",
      "568/568 [==============================] - 0s 162us/step - loss: 15322.8116 - mean_absolute_error: 93.4012 - val_loss: 37545.8599 - val_mean_absolute_error: 136.4497\n",
      "Epoch 78/200\n",
      "568/568 [==============================] - 0s 146us/step - loss: 14453.4694 - mean_absolute_error: 89.4401 - val_loss: 34723.1673 - val_mean_absolute_error: 124.5303\n",
      "Epoch 79/200\n",
      "568/568 [==============================] - 0s 162us/step - loss: 14048.3580 - mean_absolute_error: 87.4825 - val_loss: 33696.7896 - val_mean_absolute_error: 127.4484\n",
      "Epoch 80/200\n",
      "568/568 [==============================] - 0s 218us/step - loss: 13641.0046 - mean_absolute_error: 86.6235 - val_loss: 32356.2521 - val_mean_absolute_error: 124.7422\n",
      "Epoch 81/200\n",
      "568/568 [==============================] - 0s 176us/step - loss: 12979.9112 - mean_absolute_error: 84.3738 - val_loss: 31864.6359 - val_mean_absolute_error: 118.8867\n",
      "Epoch 82/200\n",
      "568/568 [==============================] - 0s 187us/step - loss: 13422.5954 - mean_absolute_error: 86.8596 - val_loss: 29758.4144 - val_mean_absolute_error: 118.4412\n",
      "Epoch 83/200\n",
      "568/568 [==============================] - 0s 240us/step - loss: 12335.0765 - mean_absolute_error: 81.8666 - val_loss: 29525.2012 - val_mean_absolute_error: 120.1018\n",
      "Epoch 84/200\n",
      "568/568 [==============================] - 0s 171us/step - loss: 11767.8969 - mean_absolute_error: 80.7361 - val_loss: 27618.3014 - val_mean_absolute_error: 113.6994\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568/568 [==============================] - 0s 179us/step - loss: 11403.7665 - mean_absolute_error: 79.7998 - val_loss: 28916.1151 - val_mean_absolute_error: 121.6244\n",
      "Epoch 86/200\n",
      "568/568 [==============================] - 0s 174us/step - loss: 10711.5473 - mean_absolute_error: 76.9463 - val_loss: 25695.3275 - val_mean_absolute_error: 110.0744\n",
      "Epoch 87/200\n",
      "568/568 [==============================] - 0s 153us/step - loss: 10270.6410 - mean_absolute_error: 75.1607 - val_loss: 28991.8493 - val_mean_absolute_error: 125.8669\n",
      "Epoch 88/200\n",
      "568/568 [==============================] - 0s 153us/step - loss: 9954.6718 - mean_absolute_error: 73.8187 - val_loss: 25134.0627 - val_mean_absolute_error: 113.3472\n",
      "Epoch 89/200\n",
      "568/568 [==============================] - 0s 150us/step - loss: 9420.7236 - mean_absolute_error: 71.9290 - val_loss: 22906.2179 - val_mean_absolute_error: 105.6915\n",
      "Epoch 90/200\n",
      "568/568 [==============================] - 0s 152us/step - loss: 8835.6231 - mean_absolute_error: 69.4545 - val_loss: 21144.5914 - val_mean_absolute_error: 100.9482\n",
      "Epoch 91/200\n",
      "568/568 [==============================] - 0s 154us/step - loss: 7821.2952 - mean_absolute_error: 66.1133 - val_loss: 18514.6667 - val_mean_absolute_error: 87.2088\n",
      "Epoch 92/200\n",
      "568/568 [==============================] - 0s 153us/step - loss: 6672.4028 - mean_absolute_error: 60.7591 - val_loss: 16163.9159 - val_mean_absolute_error: 79.4734\n",
      "Epoch 93/200\n",
      "568/568 [==============================] - 0s 152us/step - loss: 5016.9532 - mean_absolute_error: 52.4538 - val_loss: 13961.6675 - val_mean_absolute_error: 72.4876\n",
      "Epoch 94/200\n",
      "568/568 [==============================] - 0s 178us/step - loss: 3871.0088 - mean_absolute_error: 45.6564 - val_loss: 11544.8899 - val_mean_absolute_error: 59.1297\n",
      "Epoch 95/200\n",
      "568/568 [==============================] - 0s 163us/step - loss: 3149.3164 - mean_absolute_error: 42.2207 - val_loss: 10979.4657 - val_mean_absolute_error: 62.2371\n",
      "Epoch 96/200\n",
      "568/568 [==============================] - 0s 160us/step - loss: 2698.0066 - mean_absolute_error: 38.9484 - val_loss: 9721.8298 - val_mean_absolute_error: 53.1426\n",
      "Epoch 97/200\n",
      "568/568 [==============================] - 0s 158us/step - loss: 2482.7182 - mean_absolute_error: 37.3596 - val_loss: 9371.7775 - val_mean_absolute_error: 51.7353\n",
      "Epoch 98/200\n",
      "568/568 [==============================] - 0s 169us/step - loss: 2395.4661 - mean_absolute_error: 36.8393 - val_loss: 9837.4550 - val_mean_absolute_error: 52.3905\n",
      "Epoch 99/200\n",
      "568/568 [==============================] - 0s 167us/step - loss: 2320.7402 - mean_absolute_error: 36.3201 - val_loss: 9345.5307 - val_mean_absolute_error: 50.9699\n",
      "Epoch 100/200\n",
      "568/568 [==============================] - 0s 170us/step - loss: 2185.8940 - mean_absolute_error: 34.9586 - val_loss: 8589.1651 - val_mean_absolute_error: 51.0553\n",
      "Epoch 101/200\n",
      "568/568 [==============================] - 0s 175us/step - loss: 2086.0928 - mean_absolute_error: 34.5130 - val_loss: 8430.1633 - val_mean_absolute_error: 49.6521\n",
      "Epoch 102/200\n",
      "568/568 [==============================] - 0s 178us/step - loss: 2067.9074 - mean_absolute_error: 34.4429 - val_loss: 8530.6795 - val_mean_absolute_error: 48.8489\n",
      "Epoch 103/200\n",
      "568/568 [==============================] - 0s 152us/step - loss: 1979.9966 - mean_absolute_error: 33.5588 - val_loss: 8217.2567 - val_mean_absolute_error: 47.9990\n",
      "Epoch 104/200\n",
      "568/568 [==============================] - 0s 176us/step - loss: 1972.4267 - mean_absolute_error: 33.7964 - val_loss: 7981.8781 - val_mean_absolute_error: 48.4379\n",
      "Epoch 105/200\n",
      "568/568 [==============================] - 0s 171us/step - loss: 1980.9285 - mean_absolute_error: 33.7702 - val_loss: 8541.8707 - val_mean_absolute_error: 48.7980\n",
      "Epoch 106/200\n",
      "568/568 [==============================] - 0s 161us/step - loss: 1969.6446 - mean_absolute_error: 33.8458 - val_loss: 7953.4646 - val_mean_absolute_error: 50.5138\n",
      "Epoch 107/200\n",
      "568/568 [==============================] - 0s 160us/step - loss: 1913.1007 - mean_absolute_error: 33.7337 - val_loss: 7682.8932 - val_mean_absolute_error: 46.5952\n",
      "Epoch 108/200\n",
      "568/568 [==============================] - 0s 154us/step - loss: 1849.1563 - mean_absolute_error: 32.9766 - val_loss: 7897.3493 - val_mean_absolute_error: 51.1783\n",
      "Epoch 109/200\n",
      "568/568 [==============================] - 0s 155us/step - loss: 1958.4546 - mean_absolute_error: 34.2387 - val_loss: 7736.5302 - val_mean_absolute_error: 50.1793\n",
      "Epoch 110/200\n",
      "568/568 [==============================] - 0s 144us/step - loss: 1798.7208 - mean_absolute_error: 32.6560 - val_loss: 7519.3094 - val_mean_absolute_error: 45.2989\n",
      "Epoch 111/200\n",
      "568/568 [==============================] - 0s 219us/step - loss: 1859.0222 - mean_absolute_error: 33.3819 - val_loss: 7351.1132 - val_mean_absolute_error: 45.5916\n",
      "Epoch 112/200\n",
      "568/568 [==============================] - 0s 205us/step - loss: 1797.4959 - mean_absolute_error: 32.8562 - val_loss: 7284.6634 - val_mean_absolute_error: 45.2198\n",
      "Epoch 113/200\n",
      "568/568 [==============================] - 0s 235us/step - loss: 1744.7436 - mean_absolute_error: 32.1652 - val_loss: 7221.8138 - val_mean_absolute_error: 45.5156\n",
      "Epoch 114/200\n",
      "568/568 [==============================] - 0s 193us/step - loss: 1778.0440 - mean_absolute_error: 32.6254 - val_loss: 7202.8540 - val_mean_absolute_error: 46.2682\n",
      "Epoch 115/200\n",
      "568/568 [==============================] - 0s 246us/step - loss: 1732.6929 - mean_absolute_error: 32.0727 - val_loss: 7176.7156 - val_mean_absolute_error: 46.5199\n",
      "Epoch 116/200\n",
      "568/568 [==============================] - 0s 310us/step - loss: 1662.7259 - mean_absolute_error: 31.3361 - val_loss: 7015.6676 - val_mean_absolute_error: 43.8610\n",
      "Epoch 117/200\n",
      "568/568 [==============================] - 0s 231us/step - loss: 1631.1977 - mean_absolute_error: 31.2233 - val_loss: 7275.0685 - val_mean_absolute_error: 48.3385\n",
      "Epoch 118/200\n",
      "568/568 [==============================] - 0s 246us/step - loss: 1790.8393 - mean_absolute_error: 32.9833 - val_loss: 7101.0526 - val_mean_absolute_error: 43.2549\n",
      "Epoch 119/200\n",
      "568/568 [==============================] - 0s 209us/step - loss: 1697.6332 - mean_absolute_error: 31.6402 - val_loss: 7124.7982 - val_mean_absolute_error: 43.2775\n",
      "Epoch 120/200\n",
      "568/568 [==============================] - 0s 196us/step - loss: 1685.5943 - mean_absolute_error: 31.7863 - val_loss: 7432.5636 - val_mean_absolute_error: 44.7163\n",
      "Epoch 121/200\n",
      "568/568 [==============================] - 0s 199us/step - loss: 1595.9938 - mean_absolute_error: 30.8274 - val_loss: 6799.9147 - val_mean_absolute_error: 43.6065\n",
      "Epoch 122/200\n",
      "568/568 [==============================] - 0s 210us/step - loss: 1597.5858 - mean_absolute_error: 31.2156 - val_loss: 6895.0857 - val_mean_absolute_error: 42.3420\n",
      "Epoch 123/200\n",
      "568/568 [==============================] - 0s 239us/step - loss: 1533.7740 - mean_absolute_error: 30.2764 - val_loss: 6813.7021 - val_mean_absolute_error: 41.9867\n",
      "Epoch 124/200\n",
      "568/568 [==============================] - 0s 258us/step - loss: 1571.7142 - mean_absolute_error: 31.0178 - val_loss: 6659.0085 - val_mean_absolute_error: 42.0817\n",
      "Epoch 125/200\n",
      "568/568 [==============================] - 0s 245us/step - loss: 1642.7812 - mean_absolute_error: 31.2989 - val_loss: 6910.2789 - val_mean_absolute_error: 42.2482\n",
      "Epoch 126/200\n",
      "568/568 [==============================] - 0s 179us/step - loss: 1575.5648 - mean_absolute_error: 30.8226 - val_loss: 6882.7951 - val_mean_absolute_error: 42.1164\n",
      "Epoch 127/200\n",
      "568/568 [==============================] - 0s 169us/step - loss: 1476.5650 - mean_absolute_error: 29.8311 - val_loss: 6835.5444 - val_mean_absolute_error: 41.8522\n",
      "Epoch 128/200\n",
      "568/568 [==============================] - 0s 165us/step - loss: 1489.5000 - mean_absolute_error: 30.3147 - val_loss: 6447.3602 - val_mean_absolute_error: 41.6175\n",
      "Epoch 129/200\n",
      "568/568 [==============================] - 0s 167us/step - loss: 1503.5021 - mean_absolute_error: 30.1993 - val_loss: 7455.9022 - val_mean_absolute_error: 52.2290\n",
      "Epoch 130/200\n",
      "568/568 [==============================] - 0s 189us/step - loss: 1785.8601 - mean_absolute_error: 32.8448 - val_loss: 7242.9402 - val_mean_absolute_error: 44.5241\n",
      "Epoch 131/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568/568 [==============================] - 0s 177us/step - loss: 1414.7347 - mean_absolute_error: 29.7718 - val_loss: 6301.7150 - val_mean_absolute_error: 40.2394\n",
      "Epoch 132/200\n",
      "568/568 [==============================] - 0s 185us/step - loss: 1380.4853 - mean_absolute_error: 29.1217 - val_loss: 6283.7758 - val_mean_absolute_error: 40.7001\n",
      "Epoch 133/200\n",
      "568/568 [==============================] - 0s 184us/step - loss: 1535.5336 - mean_absolute_error: 30.2435 - val_loss: 6239.5274 - val_mean_absolute_error: 39.4373\n",
      "Epoch 134/200\n",
      "568/568 [==============================] - 0s 186us/step - loss: 1450.5890 - mean_absolute_error: 29.9440 - val_loss: 7143.7000 - val_mean_absolute_error: 44.2524\n",
      "Epoch 135/200\n",
      "568/568 [==============================] - 0s 168us/step - loss: 1392.4416 - mean_absolute_error: 29.2958 - val_loss: 6107.7672 - val_mean_absolute_error: 39.5125\n",
      "Epoch 136/200\n",
      "568/568 [==============================] - 0s 157us/step - loss: 1370.2811 - mean_absolute_error: 28.6907 - val_loss: 6032.2536 - val_mean_absolute_error: 38.9963\n",
      "Epoch 137/200\n",
      "568/568 [==============================] - 0s 159us/step - loss: 1405.8561 - mean_absolute_error: 29.4327 - val_loss: 6338.0013 - val_mean_absolute_error: 43.4449\n",
      "Epoch 138/200\n",
      "568/568 [==============================] - 0s 158us/step - loss: 1348.9135 - mean_absolute_error: 28.7032 - val_loss: 5906.0231 - val_mean_absolute_error: 37.9751\n",
      "Epoch 139/200\n",
      "568/568 [==============================] - 0s 159us/step - loss: 1337.0654 - mean_absolute_error: 28.6256 - val_loss: 5877.3140 - val_mean_absolute_error: 38.9488\n",
      "Epoch 140/200\n",
      "568/568 [==============================] - 0s 160us/step - loss: 1370.5227 - mean_absolute_error: 28.8957 - val_loss: 5884.9218 - val_mean_absolute_error: 37.5161\n",
      "Epoch 141/200\n",
      "568/568 [==============================] - 0s 164us/step - loss: 1304.5484 - mean_absolute_error: 28.3909 - val_loss: 5750.3778 - val_mean_absolute_error: 37.8405\n",
      "Epoch 142/200\n",
      "568/568 [==============================] - 0s 162us/step - loss: 1565.8141 - mean_absolute_error: 30.9084 - val_loss: 5746.9323 - val_mean_absolute_error: 36.9513\n",
      "Epoch 143/200\n",
      "568/568 [==============================] - 0s 173us/step - loss: 1265.1124 - mean_absolute_error: 27.9410 - val_loss: 5657.3130 - val_mean_absolute_error: 36.5913\n",
      "Epoch 144/200\n",
      "568/568 [==============================] - 0s 158us/step - loss: 1266.0736 - mean_absolute_error: 27.9150 - val_loss: 6427.5782 - val_mean_absolute_error: 41.1404\n",
      "Epoch 145/200\n",
      "568/568 [==============================] - 0s 181us/step - loss: 1262.1859 - mean_absolute_error: 27.7466 - val_loss: 5734.0453 - val_mean_absolute_error: 36.8685\n",
      "Epoch 146/200\n",
      "568/568 [==============================] - 0s 178us/step - loss: 1183.4527 - mean_absolute_error: 27.1660 - val_loss: 5566.8834 - val_mean_absolute_error: 35.9924\n",
      "Epoch 147/200\n",
      "568/568 [==============================] - 0s 170us/step - loss: 1456.4861 - mean_absolute_error: 29.7602 - val_loss: 5499.3436 - val_mean_absolute_error: 35.6717\n",
      "Epoch 148/200\n",
      "568/568 [==============================] - 0s 163us/step - loss: 1263.3307 - mean_absolute_error: 28.1428 - val_loss: 6052.5322 - val_mean_absolute_error: 39.0957\n",
      "Epoch 149/200\n",
      "568/568 [==============================] - 0s 159us/step - loss: 1182.1080 - mean_absolute_error: 27.1028 - val_loss: 5377.9413 - val_mean_absolute_error: 35.5396\n",
      "Epoch 150/200\n",
      "568/568 [==============================] - 0s 162us/step - loss: 1201.1928 - mean_absolute_error: 26.8146 - val_loss: 5331.5020 - val_mean_absolute_error: 35.1658\n",
      "Epoch 151/200\n",
      "568/568 [==============================] - 0s 166us/step - loss: 1268.1794 - mean_absolute_error: 27.6878 - val_loss: 6385.6318 - val_mean_absolute_error: 41.7247\n",
      "Epoch 152/200\n",
      "568/568 [==============================] - 0s 158us/step - loss: 1315.4033 - mean_absolute_error: 28.9655 - val_loss: 5449.2911 - val_mean_absolute_error: 35.4493\n",
      "Epoch 153/200\n",
      "568/568 [==============================] - 0s 172us/step - loss: 1115.3207 - mean_absolute_error: 26.2101 - val_loss: 6423.8625 - val_mean_absolute_error: 42.2721\n",
      "Epoch 154/200\n",
      "568/568 [==============================] - 0s 155us/step - loss: 1399.3042 - mean_absolute_error: 29.4080 - val_loss: 5520.5520 - val_mean_absolute_error: 36.0659\n",
      "Epoch 155/200\n",
      "568/568 [==============================] - 0s 173us/step - loss: 1204.8135 - mean_absolute_error: 27.1100 - val_loss: 5297.2665 - val_mean_absolute_error: 34.6536\n",
      "Epoch 156/200\n",
      "568/568 [==============================] - 0s 168us/step - loss: 1072.2464 - mean_absolute_error: 25.8689 - val_loss: 5428.0778 - val_mean_absolute_error: 35.5947\n",
      "Epoch 157/200\n",
      "568/568 [==============================] - 0s 168us/step - loss: 1119.1619 - mean_absolute_error: 26.1861 - val_loss: 5612.8139 - val_mean_absolute_error: 37.1067\n",
      "Epoch 158/200\n",
      "568/568 [==============================] - 0s 166us/step - loss: 1080.7124 - mean_absolute_error: 25.8925 - val_loss: 5748.8486 - val_mean_absolute_error: 38.1701\n",
      "Epoch 159/200\n",
      "568/568 [==============================] - 0s 163us/step - loss: 1038.1473 - mean_absolute_error: 25.0686 - val_loss: 5157.0013 - val_mean_absolute_error: 33.9769\n",
      "Epoch 160/200\n",
      "568/568 [==============================] - 0s 161us/step - loss: 1036.6905 - mean_absolute_error: 25.3298 - val_loss: 5591.9334 - val_mean_absolute_error: 37.4597\n",
      "Epoch 161/200\n",
      "568/568 [==============================] - 0s 155us/step - loss: 1113.6508 - mean_absolute_error: 26.1886 - val_loss: 5165.5765 - val_mean_absolute_error: 34.2444\n",
      "Epoch 162/200\n",
      "568/568 [==============================] - 0s 162us/step - loss: 1122.2019 - mean_absolute_error: 25.9020 - val_loss: 5004.0230 - val_mean_absolute_error: 34.5046\n",
      "Epoch 163/200\n",
      "568/568 [==============================] - 0s 153us/step - loss: 1132.5118 - mean_absolute_error: 26.3056 - val_loss: 4930.2514 - val_mean_absolute_error: 32.6343\n",
      "Epoch 164/200\n",
      "568/568 [==============================] - 0s 167us/step - loss: 1131.0066 - mean_absolute_error: 26.2937 - val_loss: 4984.6958 - val_mean_absolute_error: 34.6760\n",
      "Epoch 165/200\n",
      "568/568 [==============================] - 0s 208us/step - loss: 1112.2171 - mean_absolute_error: 26.6291 - val_loss: 4886.8111 - val_mean_absolute_error: 32.4984\n",
      "Epoch 166/200\n",
      "568/568 [==============================] - 0s 168us/step - loss: 1132.4819 - mean_absolute_error: 26.3758 - val_loss: 4794.0052 - val_mean_absolute_error: 32.5419\n",
      "Epoch 167/200\n",
      "568/568 [==============================] - 0s 172us/step - loss: 1090.3601 - mean_absolute_error: 25.4484 - val_loss: 4784.1572 - val_mean_absolute_error: 32.6862\n",
      "Epoch 168/200\n",
      "568/568 [==============================] - 0s 152us/step - loss: 1130.6760 - mean_absolute_error: 25.9599 - val_loss: 5040.1394 - val_mean_absolute_error: 34.0073\n",
      "Epoch 169/200\n",
      "568/568 [==============================] - 0s 169us/step - loss: 1032.3081 - mean_absolute_error: 25.2994 - val_loss: 4940.9704 - val_mean_absolute_error: 33.1910\n",
      "Epoch 170/200\n",
      "568/568 [==============================] - 0s 156us/step - loss: 1023.3238 - mean_absolute_error: 24.9730 - val_loss: 5009.9726 - val_mean_absolute_error: 33.8865\n",
      "Epoch 171/200\n",
      "568/568 [==============================] - 0s 191us/step - loss: 1074.1755 - mean_absolute_error: 25.4619 - val_loss: 4667.7507 - val_mean_absolute_error: 31.5582\n",
      "Epoch 172/200\n",
      "568/568 [==============================] - 0s 174us/step - loss: 1089.0292 - mean_absolute_error: 25.7224 - val_loss: 4764.9316 - val_mean_absolute_error: 33.3830\n",
      "Epoch 173/200\n",
      "568/568 [==============================] - 0s 135us/step - loss: 1069.3984 - mean_absolute_error: 25.2705 - val_loss: 7228.3008 - val_mean_absolute_error: 58.4775\n",
      "Epoch 174/200\n",
      "568/568 [==============================] - 0s 173us/step - loss: 1079.6954 - mean_absolute_error: 25.8550 - val_loss: 4637.1246 - val_mean_absolute_error: 31.5797\n",
      "Epoch 175/200\n",
      "568/568 [==============================] - 0s 139us/step - loss: 923.4111 - mean_absolute_error: 24.2256 - val_loss: 4591.1835 - val_mean_absolute_error: 31.0602\n",
      "Epoch 176/200\n",
      "568/568 [==============================] - 0s 150us/step - loss: 949.9179 - mean_absolute_error: 24.3335 - val_loss: 4651.4213 - val_mean_absolute_error: 31.1533\n",
      "Epoch 177/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568/568 [==============================] - 0s 146us/step - loss: 957.5764 - mean_absolute_error: 24.5555 - val_loss: 4668.3104 - val_mean_absolute_error: 32.5122\n",
      "Epoch 178/200\n",
      "568/568 [==============================] - 0s 156us/step - loss: 1340.1724 - mean_absolute_error: 28.5738 - val_loss: 4748.2918 - val_mean_absolute_error: 32.0505\n",
      "Epoch 179/200\n",
      "568/568 [==============================] - 0s 151us/step - loss: 911.6692 - mean_absolute_error: 23.8641 - val_loss: 4543.4990 - val_mean_absolute_error: 30.8789\n",
      "Epoch 180/200\n",
      "568/568 [==============================] - 0s 151us/step - loss: 1014.1983 - mean_absolute_error: 24.9011 - val_loss: 4926.1118 - val_mean_absolute_error: 33.7469\n",
      "Epoch 181/200\n",
      "568/568 [==============================] - 0s 151us/step - loss: 966.3626 - mean_absolute_error: 24.2448 - val_loss: 4781.6635 - val_mean_absolute_error: 34.4659\n",
      "Epoch 182/200\n",
      "568/568 [==============================] - 0s 151us/step - loss: 943.2019 - mean_absolute_error: 23.9787 - val_loss: 4716.5881 - val_mean_absolute_error: 31.6756\n",
      "Epoch 183/200\n",
      "568/568 [==============================] - 0s 162us/step - loss: 1039.9040 - mean_absolute_error: 25.1698 - val_loss: 4660.8678 - val_mean_absolute_error: 31.4461\n",
      "Epoch 184/200\n",
      "568/568 [==============================] - 0s 156us/step - loss: 907.8130 - mean_absolute_error: 23.7608 - val_loss: 4978.1818 - val_mean_absolute_error: 34.3077\n",
      "Epoch 185/200\n",
      "568/568 [==============================] - 0s 149us/step - loss: 1144.7981 - mean_absolute_error: 26.8175 - val_loss: 5346.7808 - val_mean_absolute_error: 37.2466\n",
      "Epoch 186/200\n",
      "568/568 [==============================] - 0s 152us/step - loss: 933.6858 - mean_absolute_error: 24.1753 - val_loss: 5050.6158 - val_mean_absolute_error: 34.8507\n",
      "Epoch 187/200\n",
      "568/568 [==============================] - 0s 141us/step - loss: 934.8822 - mean_absolute_error: 24.1715 - val_loss: 4419.9827 - val_mean_absolute_error: 29.9891\n",
      "Epoch 188/200\n",
      "568/568 [==============================] - 0s 138us/step - loss: 1006.1129 - mean_absolute_error: 25.1838 - val_loss: 6375.9598 - val_mean_absolute_error: 45.0959\n",
      "Epoch 189/200\n",
      "568/568 [==============================] - 0s 155us/step - loss: 957.5746 - mean_absolute_error: 24.6555 - val_loss: 4436.4529 - val_mean_absolute_error: 29.7501\n",
      "Epoch 190/200\n",
      "568/568 [==============================] - 0s 146us/step - loss: 974.2761 - mean_absolute_error: 24.3805 - val_loss: 4387.2050 - val_mean_absolute_error: 30.0328\n",
      "Epoch 191/200\n",
      "568/568 [==============================] - 0s 159us/step - loss: 986.1356 - mean_absolute_error: 24.2683 - val_loss: 4609.2117 - val_mean_absolute_error: 31.5936\n",
      "Epoch 192/200\n",
      "568/568 [==============================] - 0s 158us/step - loss: 939.3791 - mean_absolute_error: 24.1199 - val_loss: 4804.0513 - val_mean_absolute_error: 36.3634\n",
      "Epoch 193/200\n",
      "568/568 [==============================] - 0s 167us/step - loss: 922.3159 - mean_absolute_error: 23.9409 - val_loss: 4378.0041 - val_mean_absolute_error: 29.5687\n",
      "Epoch 194/200\n",
      "568/568 [==============================] - 0s 181us/step - loss: 853.9373 - mean_absolute_error: 23.1055 - val_loss: 4381.3562 - val_mean_absolute_error: 30.4588\n",
      "Epoch 195/200\n",
      "568/568 [==============================] - 0s 184us/step - loss: 981.2892 - mean_absolute_error: 24.6315 - val_loss: 4373.2287 - val_mean_absolute_error: 30.3576\n",
      "Epoch 196/200\n",
      "568/568 [==============================] - 0s 153us/step - loss: 892.5927 - mean_absolute_error: 23.6974 - val_loss: 4438.5496 - val_mean_absolute_error: 30.0092\n",
      "Epoch 197/200\n",
      "568/568 [==============================] - 0s 160us/step - loss: 808.6738 - mean_absolute_error: 22.5031 - val_loss: 4509.4177 - val_mean_absolute_error: 30.8111\n",
      "Epoch 198/200\n",
      "568/568 [==============================] - 0s 157us/step - loss: 870.8305 - mean_absolute_error: 23.4185 - val_loss: 4312.9279 - val_mean_absolute_error: 29.6682\n",
      "Epoch 199/200\n",
      "568/568 [==============================] - 0s 161us/step - loss: 879.0651 - mean_absolute_error: 23.7400 - val_loss: 4307.9122 - val_mean_absolute_error: 29.2039\n",
      "Epoch 200/200\n",
      "568/568 [==============================] - 0s 169us/step - loss: 859.4436 - mean_absolute_error: 23.1403 - val_loss: 6724.8375 - val_mean_absolute_error: 48.0572\n",
      "\n",
      "\n",
      "actual\tpredicted\n",
      "7\t46.1155\n",
      "-2\t29.3319\n",
      "-12\t40.9404\n",
      "-3\t30.1383\n",
      "20\t25.8957\n",
      "10\t33.9717\n",
      "-35\t30.9734\n",
      "-50\t29.3642\n",
      "50\t34.1808\n",
      "-25\t29.3642\n",
      "-10\t34.1808\n",
      "-10\t23.7822\n",
      "1\t30.402\n",
      "22\t19.8304\n",
      "9\t30.402\n",
      "29\t26.9319\n",
      "-12\t21.6417\n",
      "-36\t31.5401\n",
      "6\t20.8569\n",
      "30\t31.5401\n",
      "-22\t20.8569\n",
      "34\t26.4307\n",
      "-50\t19.2913\n",
      "-24\t36.9031\n",
      "9\t42.6326\n",
      "2\t36.9031\n",
      "21\t42.6326\n",
      "-25\t12.9435\n",
      "-6\t20.1299\n",
      "22\t23.6415\n",
      "-13\t20.1299\n",
      "38\t23.6415\n",
      "-50\t16.1542\n",
      "-10\t30.6569\n",
      "1\t26.0564\n",
      "3\t30.6569\n",
      "-15\t26.0564\n",
      "28\t11.894\n",
      "-7\t15.1283\n",
      "-25\t23.115\n",
      "25\t13.6294\n",
      "-11\t17.4408\n",
      "-10\t13.6294\n",
      "18\t17.4408\n",
      "-3\t15.4385\n",
      "11\t15.3288\n",
      "-2\t15.4385\n",
      "7\t19.7269\n",
      "22\t14.0258\n",
      "-9\t18.9015\n",
      "25\t20.719\n",
      "-28\t14.2893\n",
      "24\t26.7708\n",
      "44\t23.1101\n",
      "-50\t26.7708\n",
      "15\t32.9357\n",
      "25\t32.0804\n",
      "50\t32.9357\n",
      "26\t32.0804\n",
      "-6\t21.5209\n",
      "35\t26.8644\n",
      "4\t27.243\n",
      "-1\t38.8544\n",
      "-30\t26.7224\n",
      "37\t33.3542\n",
      "4\t26.7224\n",
      "-9\t33.3542\n",
      "38\t31.9127\n",
      "-17\t35.7483\n",
      "31\t41.9587\n",
      "4\t27.4077\n",
      "-13\t45.9891\n",
      "-19\t31.6492\n",
      "26\t39.583\n",
      "-24\t31.6492\n",
      "16\t39.583\n",
      "-10\t33.7284\n",
      "4\t41.7816\n",
      "33\t41.1515\n",
      "-42\t32.3151\n",
      "50\t44.0048\n",
      "50\t40.9573\n",
      "-50\t54.508\n",
      "-27\t56.6468\n",
      "0\t58.5381\n",
      "50\t56.6468\n",
      "-50\t58.5381\n",
      "50\t62.762\n",
      "-26\t61.2381\n",
      "38\t86.7618\n",
      "25\t50.5671\n",
      "3\t67.3648\n",
      "-34\t48.3888\n",
      "-1\t52.6328\n",
      "50\t55.0563\n",
      "-44\t52.6328\n",
      "-10\t78.4757\n",
      "-11\t32.0852\n",
      "-16\t61.39\n",
      "50\t32.0852\n",
      "-44\t56.7752\n",
      "-43\t71.1125\n",
      "-23\t39.149\n",
      "50\t65.8172\n",
      "3\t39.149\n",
      "-50\t80.5339\n",
      "50\t41.6538\n",
      "5\t73.6508\n",
      "-50\t41.6538\n",
      "50\t73.6508\n",
      "-38\t65.7136\n",
      "41\t64.628\n",
      "7\t65.7136\n",
      "-16\t74.3745\n",
      "-13\t55.8637\n",
      "-24\t60.6284\n",
      "-20\t55.8637\n",
      "2\t60.6284\n",
      "-5\t53.3219\n",
      "-45\t54.5178\n",
      "50\t48.6398\n",
      "10\t47.5706\n",
      "7\t53.9881\n",
      "33\t50.2424\n",
      "-6\t55.8961\n",
      "1\t59.4049\n",
      "-45\t49.3516\n",
      "-46\t56.3108\n",
      "50\t49.3516\n",
      "-39\t55.9528\n",
      "-50\t54.0205\n",
      "40\t42.949\n",
      "18\t47.014\n",
      "-22\t36.8006\n",
      "-6\t47.014\n",
      "4\t59.3386\n",
      "-50\t48.3573\n",
      "-50\t59.3386\n",
      "-50\t43.8392\n",
      "5\t48.5386\n",
      "50\t161.179\n",
      "50\t789.512\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "from math import ceil, floor\n",
    "from utils import get_data, compared_diagram\n",
    "from keras.layers import Convolution1D, Dense, MaxPooling1D, Flatten\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Tham so lien quan den neural network\n",
    "NUMBER_TIME_SERIES = 1\n",
    "NUMBER_OUTPUTS = 1\n",
    "NUMBER_FEATURE_MAPS = 4\n",
    "WINDOW_SIZE = 10\n",
    "NUMBER_NEURAL_PER_LAYER = 2\n",
    "BATCH_SIZE = 10\n",
    "NUMBER_EPOCH = 200\n",
    "\n",
    "# Tham so lien quan den du lieu dau vao\n",
    "INTERVAL_BY_SECOND = 600\n",
    "PEAK_PERCENT = 99\n",
    "START_DAY = 6\n",
    "END_DAY = 10\n",
    "\n",
    "\n",
    "# Thiet lap neural network\n",
    "def neural_network(window_size, filter_length, nb_input_series=NUMBER_TIME_SERIES,\n",
    "                   nb_outputs=NUMBER_OUTPUTS, nb_filter=NUMBER_FEATURE_MAPS):\n",
    "    model = Sequential((\n",
    "        Convolution1D(nb_filter=nb_filter, filter_length=filter_length,\n",
    "                      activation='relu', input_shape=(window_size, nb_input_series)),\n",
    "        MaxPooling1D(),\n",
    "\n",
    "        Convolution1D(nb_filter=nb_filter, filter_length=filter_length, activation='relu'),\n",
    "        MaxPooling1D(),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(nb_outputs, activation='linear'),\n",
    "    ))\n",
    "    print(window_size, nb_input_series)\n",
    "    # Su dung toi uu Adam de toi thieu MSE\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Tao input va output tu bo du lieu ban dau\n",
    "def make_timeseries_instances():\n",
    "    x = []\n",
    "    y = []\n",
    "    with open('day6_10.csv', newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        for row in reader:\n",
    "            int_row = [int(x) for x in row]\n",
    "            x.append(int_row[:-1])\n",
    "            y.append(int_row[-1])\n",
    "    x = np.atleast_3d(x)\n",
    "    q = np.atleast_3d(y)\n",
    "    y = np.asarray(y)\n",
    "    print(np.shape(x))\n",
    "    return x, y, q\n",
    "\n",
    "\n",
    "# Ham train du lieu\n",
    "def evaluate_timeseries(window_size):\n",
    "    filter_length = NUMBER_NEURAL_PER_LAYER\n",
    "    nb_filter = NUMBER_FEATURE_MAPS\n",
    "    model = neural_network(window_size=window_size,\n",
    "                           filter_length=filter_length, nb_input_series=1,\n",
    "                           nb_outputs=1, nb_filter=nb_filter)\n",
    "    model.summary()\n",
    "    x, y, q= make_timeseries_instances()\n",
    "    test_size = int(0.2 * len(y))\n",
    "    x_train, x_test, y_train, y_test = x[:-test_size], x[-test_size:], y[:-test_size], y[-test_size:]\n",
    "    model.fit(x_train, y_train, epochs=NUMBER_EPOCH, batch_size=BATCH_SIZE, validation_data=(x_test, y_test))\n",
    "    predicted_time_series = []\n",
    "    pred = model.predict(x_test)\n",
    "    print('\\n\\nactual', 'predicted', sep='\\t')\n",
    "    for actual, predicted in zip(y_test, pred.squeeze()):\n",
    "        print(actual.squeeze(), ceil(predicted), sep='\\t')\n",
    "        predicted_time_series.append(predicted)\n",
    "    return predicted_time_series\n",
    "def main():\n",
    "    # Khai bao cac tham so trong CNN\n",
    "    np.set_printoptions(threshold=25)\n",
    "    evaluate_timeseries(10)\n",
    "    # Bieu do\n",
    "    # compared_diagram(predicted_time_series, actual_time_series, WINDOW_SIZE)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
